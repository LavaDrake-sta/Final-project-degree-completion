"""
Report Generator Module - Israeli Privacy Law Compliant
Creates detailed reports of PII detection results
Compliant with Privacy Protection Law Amendment 13 (2024)
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List
from .pii_detector_il import PIIEntity
from .israeli_privacy_law import (
    get_category_hebrew_name,
    is_special_sensitivity,
    ISRAELI_PRIVACY_CATEGORIES
)


class ReportGenerator:
    """Generate reports from PII detection results"""

    def __init__(self, output_dir: str = "data/output"):
        """
        Initialize report generator

        Args:
            output_dir: Directory to save reports
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_excel_report(
        self,
        results: Dict[str, Dict],
        output_filename: str = None
    ) -> str:
        """
        Generate comprehensive Excel report

        Args:
            results: Detection results for each file
            output_filename: Custom output filename

        Returns:
            Path to generated report
        """
        if output_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"pii_report_{timestamp}.xlsx"

        output_path = self.output_dir / output_filename

        # Create Excel writer
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # Sheet 1: Summary
            summary_df = self._create_summary_dataframe(results)
            summary_df.to_excel(writer, sheet_name='×¡×™×›×•×', index=False)

            # Sheet 2: Detailed findings
            details_df = self._create_details_dataframe(results)
            details_df.to_excel(writer, sheet_name='×ž×ž×¦××™× ×ž×¤×•×¨×˜×™×', index=False)

            # Sheet 3: Statistics
            stats_df = self._create_statistics_dataframe(results)
            stats_df.to_excel(writer, sheet_name='×¡×˜×˜×™×¡×˜×™×§×”', index=False)

            # Sheet 4: Amendment 13 Compliance
            compliance_df = self._create_compliance_dataframe(results)
            compliance_df.to_excel(writer, sheet_name='×ª×™×§×•×Ÿ 13', index=False)

        print(f"âœ“ ×“×•×— × ×•×¦×¨ ×‘×”×¦×œ×—×”: {output_path}")
        return str(output_path)

    def generate_csv_report(
        self,
        results: Dict[str, Dict],
        output_filename: str = None
    ) -> str:
        """
        Generate CSV report (summary only)

        Args:
            results: Detection results for each file
            output_filename: Custom output filename

        Returns:
            Path to generated report
        """
        if output_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"pii_report_{timestamp}.csv"

        output_path = self.output_dir / output_filename

        summary_df = self._create_summary_dataframe(results)
        summary_df.to_csv(output_path, index=False, encoding='utf-8-sig')

        print(f"âœ“ ×“×•×— CSV × ×•×¦×¨ ×‘×”×¦×œ×—×”: {output_path}")
        return str(output_path)

    def _create_summary_dataframe(self, results: Dict[str, Dict]) -> pd.DataFrame:
        """Create summary DataFrame"""
        rows = []

        for filename, result in results.items():
            row = {
                '×©× ×”×§×•×‘×¥': filename,
                '×¡×•×’ ×§×•×‘×¥': result.get('file_type', 'N/A'),
                '×¡×˜×˜×•×¡': result.get('status', 'N/A')
            }

            if 'entities' in result:
                entities = result['entities']

                # Add all Israeli Privacy Law categories
                for cat_key, cat_info in ISRAELI_PRIVACY_CATEGORIES.items():
                    row[cat_info.hebrew_name] = len(entities.get(cat_key, []))

                # Calculate totals
                total_pii = sum(len(entities.get(key, [])) for key in entities.keys())
                special_count = sum(
                    len(entities.get(key, []))
                    for key in entities.keys()
                    if is_special_sensitivity(key)
                )

                row['×¡×”"×› ×¤×¨×˜×™× ××™×©×™×™×'] = total_pii
                row['×ž×™×“×¢ ×‘×¢×œ ×¨×’×™×©×•×ª ×ž×™×•×—×“×ª'] = special_count

            else:
                # No entities (error or no text)
                for cat_key, cat_info in ISRAELI_PRIVACY_CATEGORIES.items():
                    row[cat_info.hebrew_name] = 0
                row['×¡×”"×› ×¤×¨×˜×™× ××™×©×™×™×'] = 0
                row['×ž×™×“×¢ ×‘×¢×œ ×¨×’×™×©×•×ª ×ž×™×•×—×“×ª'] = 0

            rows.append(row)

        return pd.DataFrame(rows)

    def _create_details_dataframe(self, results: Dict[str, Dict]) -> pd.DataFrame:
        """Create detailed findings DataFrame"""
        rows = []

        for filename, result in results.items():
            if 'entities' not in result:
                continue

            entities = result['entities']

            for entity_type, entity_list in entities.items():
                for entity in entity_list:
                    rows.append({
                        '×©× ×”×§×•×‘×¥': filename,
                        '×¡×•×’ ×¤×¨×˜': get_category_hebrew_name(entity_type),
                        '×¡×•×’ (×× ×’×œ×™×ª)': entity_type,
                        '×¨×ž×ª ×¨×’×™×©×•×ª': '×ž×™×•×—×“×ª' if is_special_sensitivity(entity_type) else '×¨×’×™×œ×”',
                        '×¢×¨×š': entity.text,
                        '×ž×™×§×•× (×”×ª×—×œ×”)': entity.start,
                        '×ž×™×§×•× (×¡×•×£)': entity.end,
                        '×¨×ž×ª ×•×•×“××•×ª': f"{entity.confidence:.2%}"
                    })

        if not rows:
            # Return empty DataFrame with columns
            return pd.DataFrame(columns=[
                '×©× ×”×§×•×‘×¥', '×¡×•×’ ×¤×¨×˜', '×¢×¨×š',
                '×ž×™×§×•× (×”×ª×—×œ×”)', '×ž×™×§×•× (×¡×•×£)', '×¨×ž×ª ×•×•×“××•×ª'
            ])

        return pd.DataFrame(rows)

    def _create_statistics_dataframe(self, results: Dict[str, Dict]) -> pd.DataFrame:
        """Create statistics DataFrame"""

        # Count by entity type across all files
        entity_counts = {}
        total_files = len(results)
        files_with_pii = 0

        for filename, result in results.items():
            if 'entities' not in result:
                continue

            has_pii = False
            entities = result['entities']

            for entity_type, entity_list in entities.items():
                if entity_list:
                    has_pii = True

                if entity_type not in entity_counts:
                    entity_counts[entity_type] = 0

                entity_counts[entity_type] += len(entity_list)

            if has_pii:
                files_with_pii += 1

        # Create stats rows
        rows = []

        rows.append({
            '×ž×“×“': '×¡×”"×› ×§×‘×¦×™× ×©× ×¡×¨×§×•',
            '×¢×¨×š': total_files
        })

        rows.append({
            '×ž×“×“': '×§×‘×¦×™× ×¢× ×¤×¨×˜×™× ××™×©×™×™×',
            '×¢×¨×š': files_with_pii
        })

        rows.append({
            '×ž×“×“': '×§×‘×¦×™× ×œ×œ× ×¤×¨×˜×™× ××™×©×™×™×',
            '×¢×¨×š': total_files - files_with_pii
        })

        rows.append({
            '×ž×“×“': '',
            '×¢×¨×š': ''
        })

        # Add entity type counts
        hebrew_names = {
            'PERSON': '×©×ž×•×ª ×× ×©×™×',
            'ID_NUMBER': '×ª×¢×•×“×•×ª ×–×”×•×ª',
            'PHONE': '×ž×¡×¤×¨×™ ×˜×œ×¤×•×Ÿ',
            'EMAIL': '×›×ª×•×‘×•×ª ××™×ž×™×™×œ',
            'ADDRESS': '×›×ª×•×‘×•×ª',
            'CREDIT_CARD': '×›×¨×˜×™×¡×™ ××©×¨××™',
            'BANK_ACCOUNT': '×—×©×‘×•× ×•×ª ×‘× ×§',
            'ORGANIZATION': '××¨×’×•× ×™×',
            'LOCATION': '×ž×™×§×•×ž×™×'
        }

        for entity_type, count in entity_counts.items():
            rows.append({
                '×ž×“×“': hebrew_names.get(entity_type, entity_type),
                '×¢×¨×š': count
            })

        return pd.DataFrame(rows)

    def _create_compliance_dataframe(self, results: Dict[str, Dict]) -> pd.DataFrame:
        """
        Create Amendment 13 compliance report DataFrame
        Shows breakdown by sensitivity level
        """
        rows = []

        # Header
        rows.append({
            '×§×˜×’×•×¨×™×”': '×ª×™×§×•×Ÿ 13 ×œ×—×•×§ ×”×’× ×ª ×”×¤×¨×˜×™×•×ª, ×”×ª×©×¤"×“-2024',
            '×¢×¨×š': '',
            '×”×¢×¨×•×ª': '×“×•×— ×ª××™×ž×•×ª'
        })

        rows.append({'×§×˜×’×•×¨×™×”': '', '×¢×¨×š': '', '×”×¢×¨×•×ª': ''})

        # Count standard vs specially sensitive
        standard_total = 0
        special_total = 0

        standard_breakdown = {}
        special_breakdown = {}

        for filename, result in results.items():
            if 'entities' not in result:
                continue

            entities = result['entities']

            for entity_type, entity_list in entities.items():
                count = len(entity_list)
                if count == 0:
                    continue

                if is_special_sensitivity(entity_type):
                    special_total += count
                    if entity_type not in special_breakdown:
                        special_breakdown[entity_type] = 0
                    special_breakdown[entity_type] += count
                else:
                    standard_total += count
                    if entity_type not in standard_breakdown:
                        standard_breakdown[entity_type] = 0
                    standard_breakdown[entity_type] += count

        # Summary
        rows.append({
            '×§×˜×’×•×¨×™×”': '×¡×™×›×•× ×›×œ×œ×™',
            '×¢×¨×š': '',
            '×”×¢×¨×•×ª': ''
        })

        rows.append({
            '×§×˜×’×•×¨×™×”': '×¡×”"×› ×¤×¨×˜×™× ××™×©×™×™×',
            '×¢×¨×š': standard_total + special_total,
            '×”×¢×¨×•×ª': '×›×œ ×”×¤×¨×˜×™× ×©×–×•×”×•'
        })

        rows.append({
            '×§×˜×’×•×¨×™×”': '×¤×¨×˜×™× ××™×©×™×™× ×¨×’×™×œ×™×',
            '×¢×¨×š': standard_total,
            '×”×¢×¨×•×ª': '×”×’× ×” ×¡×˜× ×“×¨×˜×™×ª'
        })

        rows.append({
            '×§×˜×’×•×¨×™×”': '×ž×™×“×¢ ×‘×¢×œ ×¨×’×™×©×•×ª ×ž×™×•×—×“×ª',
            '×¢×¨×š': special_total,
            '×”×¢×¨×•×ª': '×¡×¢×™×£ 7(×’) - ×“×•×¨×© ×”×’× ×” ×ž×•×’×‘×¨×ª'
        })

        rows.append({'×§×˜×’×•×¨×™×”': '', '×¢×¨×š': '', '×”×¢×¨×•×ª': ''})

        # Standard personal information breakdown
        rows.append({
            '×§×˜×’×•×¨×™×”': '×¤×™×¨×•×˜ - ×¤×¨×˜×™× ××™×©×™×™× ×¨×’×™×œ×™×',
            '×¢×¨×š': '',
            '×”×¢×¨×•×ª': ''
        })

        for entity_type, count in standard_breakdown.items():
            rows.append({
                '×§×˜×’×•×¨×™×”': f'  â€¢ {get_category_hebrew_name(entity_type)}',
                '×¢×¨×š': count,
                '×”×¢×¨×•×ª': entity_type
            })

        if not standard_breakdown:
            rows.append({
                '×§×˜×’×•×¨×™×”': '  (×œ× × ×ž×¦××•)',
                '×¢×¨×š': 0,
                '×”×¢×¨×•×ª': ''
            })

        rows.append({'×§×˜×’×•×¨×™×”': '', '×¢×¨×š': '', '×”×¢×¨×•×ª': ''})

        # Specially sensitive information breakdown
        rows.append({
            '×§×˜×’×•×¨×™×”': '×¤×™×¨×•×˜ - ×ž×™×“×¢ ×‘×¢×œ ×¨×’×™×©×•×ª ×ž×™×•×—×“×ª (×ª×™×§×•×Ÿ 13)',
            '×¢×¨×š': '',
            '×”×¢×¨×•×ª': ''
        })

        special_categories_found = {
            'MEDICAL_INFO': '×ž×™×“×¢ ×¨×¤×•××™',
            'GENETIC_INFO': '×ž×™×“×¢ ×’× ×˜×™',
            'BIOMETRIC_ID': '×ž×–×”×” ×‘×™×•×ž×˜×¨×™',
            'SEXUAL_ORIENTATION': '× ×˜×™×™×” ×ž×™× ×™×ª',
            'POLITICAL_OPINION': '×“×¢×” ×¤×•×œ×™×˜×™×ª',
            'RELIGIOUS_BELIEF': '××ž×•× ×” ×“×ª×™×ª',
            'CRIMINAL_RECORD': '×¢×‘×¨ ×¤×œ×™×œ×™',
            'LOCATION_DATA': '× ×ª×•× ×™ ×ž×™×§×•×',
            'ETHNIC_ORIGIN': '×ž×•×¦× ××ª× ×™',
            'PERSONALITY_ASSESSMENT': '×”×¢×¨×›×ª ×ª×›×•× ×•×ª ××™×©×™×•×ª',
            'SALARY_FINANCIAL': '×©×›×¨ ×•×¤×¢×™×œ×•×ª ×›×œ×›×œ×™×ª',
            'CREDIT_CARD': '×›×¨×˜×™×¡ ××©×¨××™',
            'BANK_ACCOUNT': '×—×©×‘×•×Ÿ ×‘× ×§',
            'FAMILY_PRIVACY': '×¤×¨×˜×™×•×ª ×—×™×™ ×ž×©×¤×—×”',
            'CONFIDENTIAL_INFO': '×ž×™×“×¢ ×—×¡×•×™ ×ž×›×•×— ×“×™×Ÿ'
        }

        for cat_key, cat_name in special_categories_found.items():
            count = special_breakdown.get(cat_key, 0)
            rows.append({
                '×§×˜×’×•×¨×™×”': f'  â€¢ {cat_name}',
                '×¢×¨×š': count,
                '×”×¢×¨×•×ª': cat_key if count > 0 else ''
            })

        rows.append({'×§×˜×’×•×¨×™×”': '', '×¢×¨×š': '', '×”×¢×¨×•×ª': ''})

        # Compliance notes
        rows.append({
            '×§×˜×’×•×¨×™×”': '×”×¢×¨×•×ª ×ª××™×ž×•×ª',
            '×¢×¨×š': '',
            '×”×¢×¨×•×ª': ''
        })

        rows.append({
            '×§×˜×’×•×¨×™×”': '×ª××¨×™×š ×›× ×™×¡×” ×œ×ª×•×§×£ ×©×œ ×”×ª×™×§×•×Ÿ',
            '×¢×¨×š': '14.8.2025',
            '×”×¢×¨×•×ª': '×—×•×§ ×”×’× ×ª ×”×¤×¨×˜×™×•×ª (×ª×™×§×•×Ÿ ×ž×¡\' 13), ×”×ª×©×¤"×“-2024'
        })

        rows.append({
            '×§×˜×’×•×¨×™×”': '××—×¨×™×•×ª ×ž× ×”×œ ×ž××’×¨',
            '×¢×¨×š': '×—×•×‘×”',
            '×”×¢×¨×•×ª': '××‘×˜×—×ª ×ž×™×“×¢ ×•×”×’× ×” ×ž×•×’×‘×¨×ª ×œ×ž×™×“×¢ ×¨×’×™×©'
        })

        if special_total > 0:
            rows.append({
                '×§×˜×’×•×¨×™×”': '×”×ž×œ×¦×”',
                '×¢×¨×š': '×“×—×•×£',
                '×”×¢×¨×•×ª': f'× ×ž×¦××• {special_total} ×¤×¨×™×˜×™× ×‘×¢×œ×™ ×¨×’×™×©×•×ª ×ž×™×•×—×“×ª - × ×“×¨×©×ª ××‘×˜×—×” ×ž×•×’×‘×¨×ª'
            })

        return pd.DataFrame(rows)

    def generate_text_report(self, results: Dict[str, Dict]) -> str:
        """
        Generate human-readable text report

        Args:
            results: Detection results for each file

        Returns:
            Formatted text report
        """
        lines = []
        lines.append("=" * 80)
        lines.append("×“×•×— ×–×™×”×•×™ ×¤×¨×˜×™× ××™×©×™×™× (PII)")
        lines.append("=" * 80)
        lines.append(f"×ª××¨×™×š: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"×¡×”\"×› ×§×‘×¦×™×: {len(results)}")
        lines.append("")

        for filename, result in results.items():
            lines.append("-" * 80)
            lines.append(f"ðŸ“„ ×§×•×‘×¥: {filename}")
            lines.append(f"   ×¡×•×’: {result.get('file_type', 'N/A')}")

            if 'entities' in result:
                entities = result['entities']
                total = sum(len(elist) for elist in entities.values())

                lines.append(f"   ×¡×”\"×› ×¤×¨×˜×™× ××™×©×™×™× ×©× ×ž×¦××•: {total}")
                lines.append("")

                if total > 0:
                    lines.append("   ×¤×™×¨×•×˜:")
                    for entity_type, entity_list in entities.items():
                        if entity_list:
                            lines.append(f"   â€¢ {entity_type}: {len(entity_list)}")
                            for entity in entity_list[:3]:  # Show first 3
                                lines.append(f"     - {entity.text} (×•×•×“××•×ª: {entity.confidence:.0%})")
                            if len(entity_list) > 3:
                                lines.append(f"     ... ×•×¢×•×“ {len(entity_list) - 3}")
                else:
                    lines.append("   âœ“ ×œ× × ×ž×¦××• ×¤×¨×˜×™× ××™×©×™×™×")

            else:
                lines.append("   âš  ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×§×•×‘×¥")

            lines.append("")

        lines.append("=" * 80)

        return "\n".join(lines)

    def save_text_report(
        self,
        results: Dict[str, Dict],
        output_filename: str = None
    ) -> str:
        """
        Save text report to file

        Args:
            results: Detection results
            output_filename: Custom output filename

        Returns:
            Path to saved report
        """
        if output_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"pii_report_{timestamp}.txt"

        output_path = self.output_dir / output_filename

        report_text = self.generate_text_report(results)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_text)

        print(f"âœ“ ×“×•×— ×˜×§×¡×˜ × ×•×¦×¨ ×‘×”×¦×œ×—×”: {output_path}")
        return str(output_path)
