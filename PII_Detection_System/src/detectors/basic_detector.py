"""
PII Detection System - Basic Detector
×¤×¨×•×™×§×˜ ×’××¨ - ×–×™×”×•×™ ××™×“×¢ ××™×©×™ ×¨×’×™×©

××•×“×•×œ ×–×™×”×•×™ ×‘×¡×™×¡×™ ×¢× ×¨×’×§×¡×™× ×•××™×œ×•×ª ××¤×ª×—
××ª×•×§×Ÿ ×œ×¢×‘×•×“×” ×‘-PyCharm
"""

import re
from typing import List, Dict
from dataclasses import dataclass
from enum import Enum

class SensitivityLevel(Enum):
    """×¨××•×ª ×¨×’×™×©×•×ª ×œ××™×“×¢"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class PIIMatch:
    """×™×™×¦×•×’ ×©×œ ××™×“×¢ ×¨×’×™×© ×©× ××¦×"""
    text: str
    category: str
    start_pos: int
    end_pos: int
    confidence: float
    sensitivity: SensitivityLevel

class BasicPIIDetector:
    """
    ××–×”×” ××™×“×¢ ××™×©×™ ×‘×¡×™×¡×™ ×¢× ×¨×’×§×¡×™×
    ×’×¨×¡×” ×¤×©×•×˜×” ×•×™×¦×™×‘×”
    """

    def __init__(self):
        """××ª×—×•×œ ×”××–×”×” ×¢× ×›×œ ×”×“×¤×•×¡×™× ×•×”×—×•×§×™×"""

        # ×“×¤×•×¡×™ ×¨×’×§×¡ ×œ×–×™×”×•×™ ××™×“×¢ ××™×©×™ ×‘×¢×‘×¨×™×ª
        self.patterns = {
            'israeli_id': {
                'pattern': r'\b\d{9}\b',
                'sensitivity': SensitivityLevel.CRITICAL,
                'description': '××¡×¤×¨ ×ª×¢×•×“×ª ×–×”×•×ª ×™×©×¨××œ×™×ª'
            },
            'phone_number': {
                'pattern': r'\b0\d{1,2}-?\d{7,8}\b',
                'sensitivity': SensitivityLevel.HIGH,
                'description': '××¡×¤×¨ ×˜×œ×¤×•×Ÿ ×™×©×¨××œ×™'
            },
            'email': {
                'pattern': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
                'sensitivity': SensitivityLevel.HIGH,
                'description': '×›×ª×•×‘×ª ×“×•××¨ ××œ×§×˜×¨×•× ×™'
            },
            'credit_card': {
                'pattern': r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',
                'sensitivity': SensitivityLevel.CRITICAL,
                'description': '××¡×¤×¨ ×›×¨×˜×™×¡ ××©×¨××™ (×—×©×•×“)'
            },
            'bank_account': {
                'pattern': r'\b\d{6,12}\b',
                'sensitivity': SensitivityLevel.HIGH,
                'description': '××¡×¤×¨ ×—×©×‘×•×Ÿ ×‘× ×§ (×—×©×•×“)'
            },
            'postal_code': {
                'pattern': r'\b\d{5,7}\b',
                'sensitivity': SensitivityLevel.MEDIUM,
                'description': '××™×§×•×“'
            }
        }

        # ××™×œ×•×ª ××¤×ª×— ×¨×’×™×©×•×ª ×‘×¢×‘×¨×™×ª
        self.sensitive_keywords = {
            'medical': {
                'keywords': [
                    '×¨×•×¤×', '×‘×™×ª ×—×•×œ×™×', '××—×œ×”', '×ª×¨×•×¤×”', '××‘×—× ×”',
                    '×‘×™×˜×•×— ×‘×¨×™××•×ª', '×—×•×œ×”', '×˜×™×¤×•×œ', '×¨×¤×•××™', '××¨×¤××”',
                    '×¡×¨×˜×Ÿ', '×¡×•×›×¨×ª', '×“×™×›××•×Ÿ', '×—×¨×“×”', '×¤×¡×™×›×™××˜×¨'
                ],
                'sensitivity': SensitivityLevel.HIGH
            },
            'financial': {
                'keywords': [
                    '××©×›×•×¨×ª', '×©×›×¨', '×—×•×‘', '×”×œ×•×•××”', '××©×›× ×ª×',
                    '×—×©×‘×•×Ÿ ×‘× ×§', '××©×¨××™', '×××•×Ÿ', '×›×¡×£', '×©×§×œ',
                    '×¢×œ×•×ª', '×ª×©×œ×•×', '×—×™×•×‘', '×–×™×›×•×™'
                ],
                'sensitivity': SensitivityLevel.HIGH
            },
            'personal': {
                'keywords': [
                    '×’×™×¨×•×©×™×Ÿ', '××–×•× ×•×ª', '×˜×™×¤×•×œ ×¤×¡×™×›×•×œ×•×’×™', '×™×—×¡×™×',
                    '××©×¤×—×”', '×™×œ×“×™×', '×”×•×¨×™×', '× ×©×•×™', '×¨×•×•×§',
                    '×¤×¨×˜×™', '×¡×•×“×™', '××™×©×™'
                ],
                'sensitivity': SensitivityLevel.MEDIUM
            },
            'identification': {
                'keywords': [
                    '×ª×¢×•×“×ª ×–×”×•×ª', '×ª.×–', '×“×¨×›×•×Ÿ', '×¨×™×©×™×•×Ÿ × ×”×™×’×”',
                    '××¡×¤×¨ ×–×”×•×ª', '×ª×–', '×–×”×•×ª', '×ª×¢×•×“×”'
                ],
                'sensitivity': SensitivityLevel.CRITICAL
            }
        }

    def detect_patterns(self, text: str) -> List[PIIMatch]:
        """×–×™×”×•×™ ×“×¤×•×¡×™× ×‘×××¦×¢×•×ª ×‘×™×˜×•×™×™× ×¨×’×•×œ×¨×™×™×"""
        matches = []

        for category, pattern_info in self.patterns.items():
            pattern = pattern_info['pattern']

            try:
                for match in re.finditer(pattern, text, re.IGNORECASE):
                    pii_match = PIIMatch(
                        text=match.group(),
                        category=category,
                        start_pos=match.start(),
                        end_pos=match.end(),
                        confidence=0.9,  # ×¨××ª ×•×“××•×ª ×’×‘×•×”×” ×œ×¨×’×§×¡×™×
                        sensitivity=pattern_info['sensitivity']
                    )
                    matches.append(pii_match)
            except Exception as e:
                print(f"×©×’×™××” ×‘×–×™×”×•×™ ×“×¤×•×¡ {category}: {e}")
                continue

        return matches

    def detect_keywords(self, text: str) -> List[PIIMatch]:
        """×–×™×”×•×™ ××™×œ×•×ª ××¤×ª×— ×¨×’×™×©×•×ª"""
        matches = []
        text_lower = text.lower()

        for category, keyword_info in self.sensitive_keywords.items():
            for keyword in keyword_info['keywords']:
                keyword_lower = keyword.lower()

                # ×—×™×¤×•×© ×›×œ ×”××•×¤×¢×™× ×©×œ ×”××™×œ×”
                start_pos = 0
                while True:
                    pos = text_lower.find(keyword_lower, start_pos)
                    if pos == -1:
                        break

                    pii_match = PIIMatch(
                        text=keyword,
                        category=f"keyword_{category}",
                        start_pos=pos,
                        end_pos=pos + len(keyword),
                        confidence=0.6,  # ×¨××ª ×•×“××•×ª × ××•×›×” ×™×•×ª×¨ ×œ××™×œ×•×ª ××¤×ª×—
                        sensitivity=keyword_info['sensitivity']
                    )
                    matches.append(pii_match)
                    start_pos = pos + 1

        return matches

    def analyze_text(self, text: str) -> Dict:
        """× ×™×ª×•×— ×˜×§×¡×˜ ××œ× - ×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª"""
        if not text or not text.strip():
            return {
                'matches': [],
                'total_matches': 0,
                'overall_sensitivity': SensitivityLevel.LOW,
                'summary': "×œ× ×”×•×–×Ÿ ×˜×§×¡×˜ ×œ×‘×“×™×§×”"
            }

        try:
            # ×–×™×”×•×™ ×“×¤×•×¡×™× ×•××™×œ×•×ª ××¤×ª×—
            pattern_matches = self.detect_patterns(text)
            keyword_matches = self.detect_keywords(text)

            # ××™×—×•×“ ×›×œ ×”×××¦××™×
            all_matches = pattern_matches + keyword_matches

            # ×”×¡×¨×ª ×›×¤×™×œ×•×™×•×ª (××•×ª×• ×˜×§×¡×˜ ×‘××•×ª×• ××™×§×•×)
            unique_matches = []
            seen = set()

            for match in all_matches:
                match_key = (match.text, match.start_pos, match.category)
                if match_key not in seen:
                    unique_matches.append(match)
                    seen.add(match_key)

            # ×—×™×©×•×‘ ×¨××ª ×¨×’×™×©×•×ª ×›×œ×œ×™×ª
            if not unique_matches:
                overall_sensitivity = SensitivityLevel.LOW
            else:
                max_sensitivity = max(match.sensitivity.value for match in unique_matches)
                overall_sensitivity = SensitivityLevel(max_sensitivity)

            # ×™×¦×™×¨×ª ×¡×™×›×•×
            summary = self._generate_summary(unique_matches)

            return {
                'matches': unique_matches,
                'total_matches': len(unique_matches),
                'overall_sensitivity': overall_sensitivity,
                'summary': summary,
                'text_length': len(text),
                'words_count': len(text.split())
            }

        except Exception as e:
            return {
                'matches': [],
                'total_matches': 0,
                'overall_sensitivity': SensitivityLevel.LOW,
                'summary': f"×©×’×™××” ×‘× ×™×ª×•×— ×”×˜×§×¡×˜: {str(e)}",
                'error': str(e)
            }

    def _generate_summary(self, matches: List[PIIMatch]) -> str:
        """×™×¦×™×¨×ª ×¡×™×›×•× ×”×××¦××™×"""
        if not matches:
            return "âœ… ×œ× × ××¦× ××™×“×¢ ×¨×’×™×© ×‘×˜×§×¡×˜"

        # ×¡×¤×™×¨×” ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª
        categories = {}
        critical_count = 0
        high_count = 0

        for match in matches:
            category = match.category
            categories[category] = categories.get(category, 0) + 1

            if match.sensitivity == SensitivityLevel.CRITICAL:
                critical_count += 1
            elif match.sensitivity == SensitivityLevel.HIGH:
                high_count += 1

        # ×‘× ×™×™×ª ×”×¡×™×›×•×
        summary = f"âš ï¸ × ××¦××• {len(matches)} ×¤×¨×™×˜×™ ××™×“×¢ ×¨×’×™×©"

        if critical_count > 0:
            summary += f" (×›×•×œ×œ {critical_count} ×§×¨×™×˜×™×™×)"
        elif high_count > 0:
            summary += f" (×›×•×œ×œ {high_count} ×‘×¨××” ×’×‘×•×”×”)"

        return summary

    def get_statistics(self, matches: List[PIIMatch]) -> Dict:
        """×¡×˜×˜×™×¡×˜×™×§×•×ª ××¤×•×¨×˜×•×ª ×¢×œ ×”×××¦××™×"""
        if not matches:
            return {}

        stats = {
            'by_sensitivity': {},
            'by_category': {},
            'confidence_avg': 0
        }

        # ×¡×¤×™×¨×” ×œ×¤×™ ×¨××ª ×¨×’×™×©×•×ª
        for match in matches:
            sens_name = match.sensitivity.name
            stats['by_sensitivity'][sens_name] = stats['by_sensitivity'].get(sens_name, 0) + 1

            # ×¡×¤×™×¨×” ×œ×¤×™ ×§×˜×’×•×¨×™×”
            category = match.category.replace('_', ' ').title()
            stats['by_category'][category] = stats['by_category'].get(category, 0) + 1

        # ×—×™×©×•×‘ ×××•×¦×¢ ×¨××ª ×•×“××•×ª
        if matches:
            stats['confidence_avg'] = sum(match.confidence for match in matches) / len(matches)

        return stats

# ×“×•×’××” ×œ×©×™××•×© ×•×‘×“×™×§×”
if __name__ == "__main__":
    print("ğŸ” ×‘×“×™×§×ª ××•×“×•×œ ×–×™×”×•×™ ×”××™×“×¢ ×”×¨×’×™×©")
    print("=" * 40)

    # ×™×¦×™×¨×ª ××–×”×”
    detector = BasicPIIDetector()

    # ×“×•×’×××•×ª ×œ×‘×“×™×§×”
    test_cases = [
        "×©×œ×•×, ×× ×™ ×™×•×¡×™ ×›×”×Ÿ ×•××¡×¤×¨ ×”×–×”×•×ª ×©×œ×™ ×”×•× 123456789",
        "××¤×©×¨ ×œ×”×ª×§×©×¨ ××œ×™×™ ×‘×˜×œ×¤×•×Ÿ 052-1234567 ××• ×œ×©×œ×•×— ××™××™×™×œ ×œ yossi@example.com",
        "×× ×™ ×¢×•×‘×“ ×‘×—×‘×¨×ª ×”×™×™×˜×§ ×•××¨×•×•×™×— 15,000 ×©×§×œ ×‘×—×•×“×©",
        "×”×©×‘×•×¢ ×”×œ×›×ª×™ ×œ×¨×•×¤× ×‘×’×œ×œ ××—×œ×” ×›×¨×•× ×™×ª",
        "××¡×¤×¨ ×”×›×¨×˜×™×¡ ×©×œ×™ ×”×•× 4580-1234-5678-9012"
    ]

    for i, text in enumerate(test_cases, 1):
        print(f"\n{i}. ×‘×“×™×§×ª ×˜×§×¡×˜: '{text}'")
        results = detector.analyze_text(text)
        print(f"   {results['summary']}")
        print(f"   ×¨××ª ×¨×’×™×©×•×ª: {results['overall_sensitivity'].name}")

        if results['matches']:
            for match in results['matches']:
                print(f"   ğŸ” '{match.text}' â†’ {match.category} (×•×“××•×ª: {match.confidence:.0%})")

    print("\nâœ… ×‘×“×™×§×ª ×”××•×“×•×œ ×”×•×©×œ××” ×‘×”×¦×œ×—×”!")